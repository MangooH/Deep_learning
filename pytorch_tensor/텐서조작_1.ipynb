{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 텐서조작"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 목표\n",
    "- `Generating Tensor`: 텐서의 생성 및 다양한 타입을 텐서로 변환할 수 있다.\n",
    "- `Reshaping Tensor`: 텐서의 모양을 변경하고 구현할 수 있다.\n",
    "    - 데이터 전처리\n",
    "    - 신경망 층 간 연결\n",
    "    - Feature Engineering\n",
    "- `Merging & Spliting Tensor`: 텐서를 합치거나 나누거나 할 수 있다.\n",
    "    - 데이터 배치 처리\n",
    "    - 다중 입력/출력 모델\n",
    "    - 교차 검증 및 데이터 분할"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 목차\n",
    "1. `텐서 이해하기`\n",
    "    - 텐서를 생성하고 텐서로 변환하는 방법을 이해\n",
    "    - 텐서에서의 indexing 이해\n",
    "2. `텐서의 모양 바꾸기`\n",
    "    - 텐서의 shape 을 바꾸는 여러가지 함수 이해\n",
    "    - 텐서의 차원을 추가하거나 변경하는 방법에 대한 이해\n",
    "    - 역할이 비슷한 함수들의 차이 이해\n",
    "3. `텐서 합치기와 나누기`\n",
    "    - 여러 텐서를 합치는 방법에 대한 이해\n",
    "    - 하나의 텐서를 여러개로 나누는 방법에 대한 이해"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch # PyTorch 불러오기\n",
    "import numpy as np # numpy 불러오기\n",
    "import warnings # 경고 문구 제거\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 텐서 이해하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-1 텐서를 생성하고 변환하는 방법을 이해\n",
    "> Random 값을 갖는 텐서를 생성하고, list 나 numpy array 같은 다양한 형태의 배열들을 Pytorch 를 이용하여 텐서로 변환하는 과정을 알아본다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "💡 텐서의 값을 무작위로 생성하는 방법:\n",
    "\n",
    "- `rand`: 0과 1 사이의 균일한 분포(uniform Distribution)에서 무작위로 생성된 텐서를 반환\n",
    "- `randn`: 평균이 0이고 표준편차가 1인 정규분포(Gaussian Distribution)에서 무작위로 생성된 텐서를 반환\n",
    "- `randint`: 주어진 범위 내에서 정수값을 무작위로 선택하여 생성된 텐서를 반환 **(min <= values < max)**\n",
    "\n",
    "📚 Reference: \n",
    "- `rand`: https://pytorch.org/docs/stable/generated/torch.rand.html\n",
    "- `randn`: https://pytorch.org/docs/stable/generated/torch.randn.html\n",
    "- `randont`: https://pytorch.org/docs/stable/generated/torch.randint.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4784, 0.4023, 0.9215],\n",
      "        [0.8415, 0.4990, 0.7861]])\n",
      "tensor([[-1.8215,  0.6000, -1.0479],\n",
      "        [-0.0432, -2.2551,  2.0587]])\n",
      "tensor([[5, 5, 3],\n",
      "        [8, 3, 6]])\n"
     ]
    }
   ],
   "source": [
    "# N x M 텐서로 반환\n",
    "print(torch.rand(2,3))\n",
    "print(torch.randn(2,3))\n",
    "print(torch.randint(1, 10, (2, 3))) # 생성가능한 최소값 1, 최대값 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "💡 텐서의 값을 지정해서 생성하는 방법:\n",
    "* `zeros` : 모든 요소가 0인 텐서 반환\n",
    "* `ones`: 모든 요소가 1인 텐서 반환\n",
    "* `full`: 모든 요소가 지정된 값인 텐서 반환\n",
    "* `eye`: 단위 행렬 반환 (**대각선 요소가 1**이고 나머지 요소가 0인 행렬)\n",
    "\n",
    "\n",
    "📚 Reference: \n",
    "* `zeros` https://pytorch.org/docs/stable/generated/torch.zeros.html\n",
    "* `ones` https://pytorch.org/docs/stable/generated/torch.ones.html\n",
    "* `full` https://pytorch.org/docs/stable/generated/torch.full.html\n",
    "* `eye` https://pytorch.org/docs/stable/generated/torch.eye.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.zeros(*size) -> \",\" 로 구분하여 차원을 여러개로 늘릴 수 있다.\n",
    "torch.zeros(3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1.],\n",
       "         [1., 1.]],\n",
       "\n",
       "        [[1., 1.],\n",
       "         [1., 1.]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.zeros(*size) \n",
    "torch.ones(2, 2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5, 5, 5],\n",
       "        [5, 5, 5]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.full((size), value)\n",
    "torch.full((2, 3), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 단위행렬 특성 상 정사각행렬(square matrix)만 가능\n",
    "torch.eye(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "💡 다양한 데이터를 텐서 형식으로 변환:\n",
    "* `tensor` : 주어진 데이터를 텐서로 변환. 데이터는 list, tuple, numpy array 등의 형태일 수 있다.\n",
    "* `from_numpy`: numpy array 를 텐서로 변환\n",
    "\n",
    "\n",
    "📚 Reference: \n",
    "* `tensor` https://pytorch.org/docs/stable/generated/torch.tensor.html\n",
    "* `from_numpy` https://pytorch.org/docs/stable/generated/torch.from_numpy.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1,  2,  3,  4,  5],\n",
      "        [ 6,  7,  8,  9, 10]])\n",
      "\n",
      "\n",
      "tensor([1, 2, 3])\n",
      "\n",
      "\n",
      "tensor([[[ 1,  2,  3],\n",
      "         [ 4,  5,  6]],\n",
      "\n",
      "        [[ 7,  8,  9],\n",
      "         [10, 11, 12]]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# list, tuple, numpy array 를 텐서로 바꾸기\n",
    "ls = [[1,2,3,4,5], [6,7,8,9,10]]\n",
    "tup = (1,2,3)\n",
    "arr = np.array([[[1,2,3], [4,5,6,]], [[7,8,9], [10,11,12]]])\n",
    "\n",
    "print(torch.tensor(ls))\n",
    "print('\\n')\n",
    "print(torch.tensor(tup))\n",
    "print('\\n')\n",
    "print(torch.tensor(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1,  2,  3],\n",
       "         [ 4,  5,  6]],\n",
       "\n",
       "        [[ 7,  8,  9],\n",
       "         [10, 11, 12]]], dtype=torch.int32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# array to tensor\n",
    "torch.from_numpy(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "💡 다양한 형식의 텐서 변환:\n",
    "* `as_tensor` : 변환 전 데이터와의 메모리 공유(memory sharing)를 사용하여, 변환 전 데이터 변경 시 변환되어있는 텐서에서도 반영됨\n",
    "* `Tensor`: float32 type 으로 텐서 변환\n",
    "\n",
    "\n",
    "📚 Reference: \n",
    "* [as_tensor] https://pytorch.org/docs/stable/generated/torch.as_tensor.html\n",
    "* [Tensor] https://pytorch.org/docs/stable/tensors.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.tensor\n",
      "tensor([1, 2, 3, 4, 5], dtype=torch.int32)\n",
      "-----------------------------------\n",
      "torch.as_tensor\n",
      "tensor([10,  2,  3,  4,  5], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# torch.tensor 와 torch.as_tensor 의 차이점 알아보기\n",
    "print('torch.tensor')\n",
    "d1 = np.array([1,2,3,4,5])\n",
    "tensor1 = torch.tensor(d1)\n",
    "d1[0] = 10\n",
    "print(tensor1) # 원본 데이터의 값 변경에 영향을 받지 않음\n",
    "\n",
    "print('-------'*5)\n",
    "\n",
    "print('torch.as_tensor')\n",
    "d2 = np.array([1,2,3,4,5])\n",
    "tensor1 = torch.as_tensor(d1) # 메모리 공유\n",
    "d2[0] = 10\n",
    "print(tensor1) # 원본 데이터의 값 변경에 영향을 받음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.tensor\n",
      "Output: tensor([1, 2, 3, 4, 5])\n",
      "Type torch.int64\n",
      "torch.Tensor\n",
      "Output: tensor([1., 2., 3., 4., 5.])\n",
      "Type torch.float32\n"
     ]
    }
   ],
   "source": [
    "data = [1,2,3,4,5]\n",
    "tensor1 = torch.tensor(data)\n",
    "print('torch.tensor')\n",
    "print(\"Output:\", tensor1)\n",
    "print(\"Type\", tensor1.dtype) # 원본의 데이터 타입을 그대로 변환\n",
    "\n",
    "tensor2 = torch.Tensor(data)\n",
    "print('torch.Tensor')\n",
    "print(\"Output:\", tensor2)\n",
    "print(\"Type\", tensor2.dtype) # float32 타입의 Tensor 로 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-2 텐서에서 Indexing 을 이해\n",
    "> Indexing 개념과 Indexing 을 통해 값을 변경하는 방법에 대해 이해한다.\n",
    "- Indexing 은 텐서 내의 특정 **요소**에 index를 통해 접근할 수 있는 방법을 의미한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "💡 Indexing 이란?:\n",
    "- `Indexing 기본`: **대괄호(\"[]\")**를 통해 이루어지며, **\":\"** 는 특정 범위의 접근을 의미한다.\n",
    "- `index_select`: 선택한 차원에서 인덱스에 해당하는 요소만을 추출하는 함수\n",
    "- `masking 을 이용한 Indexing`: 조건에 맞는 요소들만 반환하는 방법\n",
    "- `masked_select`: 주어진 mask에 해당하는 요소들을 추출하여 1차원으로 펼친 새로운 텐서를 반환하는 함수\n",
    "- `take`: 주어진 인덱스를 사용하여 텐서에서 요소를 선택하는 함수. 인덱스 번호는 텐서를 1차원으로 늘려졌을 때 기준으로 접근해야한다.\n",
    "- `gather`: 주어진 차원에서 인덱스에 해당하는 요소들을 선택하여 새로운 텐서를 반환\n",
    "\n",
    "\n",
    "📚 Reference: \n",
    "* [Tensor indexing] : https://pytorch.org/cppdocs/notes/tensor_indexing.html\n",
    "* [index_select] : https://pytorch.org/docs/stable/generated/torch.index_select.html\n",
    "* [masked_select] : https://pytorch.org/docs/stable/generated/torch.masked_select.html\n",
    "* [take] : https://pytorch.org/docs/stable/generated/torch.take.html\n",
    "* [gather] : https://pytorch.org/docs/stable/generated/torch.gather.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0)\n",
      "tensor(9)\n",
      "tensor([2, 3])\n"
     ]
    }
   ],
   "source": [
    "# 1차원 텐서에서 Indexing\n",
    "tmp_1dim = torch.tensor([i for i in range(10)]) # 0~9 의 값을 갖는 1차원 텐서 생성\n",
    "\n",
    "print(tmp_1dim[0])\n",
    "print(tmp_1dim[-1])\n",
    "print(tmp_1dim[2:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  torch.Size([4, 3, 2])\n",
      "tensor([[[0, 3],\n",
      "         [5, 7],\n",
      "         [0, 6]],\n",
      "\n",
      "        [[8, 5],\n",
      "         [2, 0],\n",
      "         [7, 9]],\n",
      "\n",
      "        [[3, 1],\n",
      "         [8, 1],\n",
      "         [3, 3]],\n",
      "\n",
      "        [[9, 4],\n",
      "         [3, 4],\n",
      "         [5, 7]]])\n",
      "--------------------------------------------------------\n",
      "torch.Size([4, 3])\n",
      "tensor([[0, 5, 0],\n",
      "        [8, 2, 7],\n",
      "        [3, 8, 3],\n",
      "        [9, 3, 5]])\n",
      "\n",
      "\n",
      "torch.Size([3])\n",
      "tensor([3, 7, 6])\n"
     ]
    }
   ],
   "source": [
    "# n 차원 텐서 Indexing\n",
    "tmp_3dim = torch.randint(0, 10, (4,3,2)) # 4채널, 3행, 2열\n",
    "print(\"Shape: \", tmp_3dim.shape)\n",
    "print(tmp_3dim)\n",
    "\n",
    "print('-------'*8)\n",
    "\n",
    "# 전체 채널과 전체 행에서 0번째 열만 추출\n",
    "print(tmp_3dim[:,:,0].shape)\n",
    "print(tmp_3dim[:,:,0])\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "# 0번째 채널의 전체 행에서 1번째 열만 추출\n",
    "print(tmp_3dim[0,:,1].shape)\n",
    "print(tmp_3dim[0,:,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4, 6, 5, 2],\n",
      "        [3, 9, 2, 6],\n",
      "        [8, 2, 6, 6]])\n",
      "\n",
      "\n",
      "tensor([[4, 5],\n",
      "        [3, 2],\n",
      "        [8, 6]])\n",
      "\n",
      "\n",
      "tensor([[4, 6, 5, 2],\n",
      "        [8, 2, 6, 6]])\n"
     ]
    }
   ],
   "source": [
    "# index_select\n",
    "# 열을 기준으로 0열과 2열을 추출\n",
    "tmp_2dim = torch.randint(0, 10, (3, 4))\n",
    "print(tmp_2dim)\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "my_index = torch.tensor([0, 2]) # 선택하고자 하는 index 는 텐서 형태이어야함.\n",
    "print(torch.index_select(tmp_2dim, dim=1, index=my_index)) # 열추출\n",
    "print('\\n')\n",
    "print(torch.index_select(tmp_2dim, dim=0, index=my_index)) # 행추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 5, 9, 6, 8, 6, 6])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mask 를 이용한 텐서 Indexing (조건에 맞는 값만 추출)\n",
    "mask = tmp_2dim >= 5 # 5보다 큰 텐서만 추출\n",
    "tmp_2dim[mask] # 1차원 Tensor 로 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 5, 9, 6, 8, 6, 6])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# masked_select\n",
    "torch.masked_select(tmp_2dim, mask=mask) # tmp_2dim[tmp_2dim >= 5] 와 동일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
      "        [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]])\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  5, 10, 15])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take\n",
    "# Tensor 가 1차원으로 늘려졌을 때 기준으로 index 번호로 접근\n",
    "tem_2dim = torch.tensor([[i for i in range(10)], [i for i in range(10, 20)]])\n",
    "print(tem_2dim)\n",
    "print('\\n')\n",
    "idx = torch.tensor([0, 5, 10, 15])\n",
    "torch.take(tem_2dim, index=idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1],\n",
       "        [15, 18]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gather\n",
    "# 행 또는 열의 index 를 각각(모두) 설정한다.\n",
    "gather_idx = torch.tensor([[0, 1], [5,8]]) \n",
    "torch.gather(tem_2dim, dim=1, index=gather_idx)\n",
    "# dim=1 을 기준으로 첫 행의 0, 1 번째, 두 번째 행의 5, 8 번째 indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 텐서의 모양 바꾸기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1. 텐서의 shape 을 바꾸는 여러가지 함수 이해\n",
    "> 텐서의 모양을 자유자재로 바꾸는 방법에 대해 알아본다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "💡 텐서의 shape 변경:\n",
    "> 텐서에 대한 모양을 변경할 때 **텐서의 크기(요소의 개수)가 유지되어야 한다**\n",
    "* `size`: 텐서의 모양을 확인한다.\n",
    "* `reshape`: 텐서의 모양을 변경한다. (메모리를 공유하지 않는다)\n",
    "* `view`: 텐서의 모양을 변경한다.\n",
    "* `transpose`: 텐서의 차원을 전치한다.\n",
    "* `permute`: 텐서의 차원의 순서를 재배열한다.\n",
    "\n",
    "📚 Reference: \n",
    "* [size] : https://pytorch.org/docs/stable/generated/torch.Tensor.size.html\n",
    "* [reshape] : https://pytorch.org/docs/stable/generated/torch.reshape.html\n",
    "* [view] : https://pytorch.org/docs/stable/generated/torch.Tensor.view.html\n",
    "* [transpose] : https://pytorch.org/docs/stable/generated/torch.transpose.html\n",
    "* [permute] : https://pytorch.org/docs/stable/generated/torch.permute.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 5])\n",
      "torch.Size([2, 3, 5])\n"
     ]
    }
   ],
   "source": [
    "# size, # shape\n",
    "print(torch.randn(2, 3, 5).size())\n",
    "print(torch.randn(2, 3, 5).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.9311, -0.7279,  0.1766,  0.1792,  0.1511],\n",
      "         [ 2.1681,  0.6011,  0.5407, -0.5879, -0.8650],\n",
      "         [ 0.8555, -0.0207,  0.5178, -1.2998,  0.2312]],\n",
      "\n",
      "        [[ 0.1731,  0.4273, -0.7035,  1.0637, -1.7200],\n",
      "         [-1.2022,  1.0715, -1.4845, -0.4681, -0.9905],\n",
      "         [-0.2045,  2.1790,  2.0393, -1.5453, -0.0882]]])\n",
      "Shape:  torch.Size([2, 3, 5])\n",
      "\n",
      "\n",
      "tensor([[ 0.9311, -0.7279,  0.1766,  0.1792,  0.1511,  2.1681],\n",
      "        [ 0.6011,  0.5407, -0.5879, -0.8650,  0.8555, -0.0207],\n",
      "        [ 0.5178, -1.2998,  0.2312,  0.1731,  0.4273, -0.7035],\n",
      "        [ 1.0637, -1.7200, -1.2022,  1.0715, -1.4845, -0.4681],\n",
      "        [-0.9905, -0.2045,  2.1790,  2.0393, -1.5453, -0.0882]])\n",
      "Shape:  torch.Size([5, 6])\n",
      "\n",
      "\n",
      "tensor([[ 0.9311, -0.7279,  0.1766,  0.1792,  0.1511,  2.1681],\n",
      "        [ 0.6011,  0.5407, -0.5879, -0.8650,  0.8555, -0.0207],\n",
      "        [ 0.5178, -1.2998,  0.2312,  0.1731,  0.4273, -0.7035],\n",
      "        [ 1.0637, -1.7200, -1.2022,  1.0715, -1.4845, -0.4681],\n",
      "        [-0.9905, -0.2045,  2.1790,  2.0393, -1.5453, -0.0882]])\n",
      "Shape:  torch.Size([5, 6])\n"
     ]
    }
   ],
   "source": [
    "# 모양 변경 - reshape & view\n",
    "a = torch.randn(2, 3, 5)\n",
    "print(a)\n",
    "print(\"Shape: \", a.size())\n",
    "print('\\n')\n",
    "\n",
    "# 2 * 3 * 5 = 30\n",
    "reshape_a = a.reshape(5, 6) # 3 차원 텐서를 2차원 텐서로 크기 변경\n",
    "print(reshape_a)\n",
    "print(\"Shape: \", reshape_a.size())\n",
    "print('\\n')\n",
    "\n",
    "view_a = a.view(5, 6) # 3 차원 텐서를 2차원 텐서로 크기 변경\n",
    "print(view_a)\n",
    "print(\"Shape: \", view_a.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 10])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -1 로 모양 자동 설정 \n",
    "reshape_auto_a = a.reshape(3, -1)\n",
    "reshape_auto_a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[5, 7, 7, 1, 1],\n",
      "         [6, 8, 6, 5, 3]],\n",
      "\n",
      "        [[9, 5, 4, 1, 9],\n",
      "         [1, 6, 7, 5, 8]],\n",
      "\n",
      "        [[3, 1, 6, 8, 9],\n",
      "         [9, 3, 1, 3, 3]]])\n",
      "Shape:  torch.Size([3, 2, 5])\n",
      "\n",
      "\n",
      "tensor([[[5, 6],\n",
      "         [7, 8],\n",
      "         [7, 6],\n",
      "         [1, 5],\n",
      "         [1, 3]],\n",
      "\n",
      "        [[9, 1],\n",
      "         [5, 6],\n",
      "         [4, 7],\n",
      "         [1, 5],\n",
      "         [9, 8]],\n",
      "\n",
      "        [[3, 9],\n",
      "         [1, 3],\n",
      "         [6, 1],\n",
      "         [8, 3],\n",
      "         [9, 3]]])\n",
      "Shape:  torch.Size([3, 5, 2])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tensor_a = torch.randint(1, 10, (3, 2, 5))\n",
    "print(tensor_a)\n",
    "print(\"Shape: \", tensor_a.size())\n",
    "print('\\n')\n",
    "\n",
    "# transpose(전치) -> 서로 전치할 차원 2개를 지정\n",
    "trans_tensor_a = tensor_a.transpose(1, 2) # (3, 2, 5) -> (3, 5, 2)\n",
    "print(trans_tensor_a)\n",
    "print(\"Shape: \", trans_tensor_a.size())\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[5, 7, 7, 1, 1],\n",
      "         [6, 8, 6, 5, 3]],\n",
      "\n",
      "        [[9, 5, 4, 1, 9],\n",
      "         [1, 6, 7, 5, 8]],\n",
      "\n",
      "        [[3, 1, 6, 8, 9],\n",
      "         [9, 3, 1, 3, 3]]])\n",
      "Shape:  torch.Size([3, 2, 5])\n",
      "\n",
      "\n",
      "tensor([[[5, 6],\n",
      "         [7, 8],\n",
      "         [7, 6],\n",
      "         [1, 5],\n",
      "         [1, 3]],\n",
      "\n",
      "        [[9, 1],\n",
      "         [5, 6],\n",
      "         [4, 7],\n",
      "         [1, 5],\n",
      "         [9, 8]],\n",
      "\n",
      "        [[3, 9],\n",
      "         [1, 3],\n",
      "         [6, 1],\n",
      "         [8, 3],\n",
      "         [9, 3]]])\n",
      "Shape:  torch.Size([3, 5, 2])\n"
     ]
    }
   ],
   "source": [
    "# permute - shape 변경\n",
    "print(tensor_a)\n",
    "print(\"Shape: \", tensor_a.size())\n",
    "print('\\n')\n",
    "\n",
    "permute_a = tensor_a.permute(0, 2, 1) # (3, 2, 5) -> (3, 5, 2)\n",
    "print(permute_a)\n",
    "print(\"Shape: \", permute_a.size())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2. 텐서의 차원을 추가하거나 변경하는 방법에 대한 이해\n",
    "> 텐서의 차원 변경 방식에 대한 이해와 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "💡 텐서의 차원을 추가하거나 변경하는 방법에 대한 이해 및 실습:\n",
    "- `unsqueeze`: 텐서에 특정 차원에 크기가 1인 차원을 추가한다.\n",
    "- `squeeze`: 텐서에 차원의 크기가 1인 차원을 제거한다.\n",
    "- `expand`: 텐서의 값을 반복하여 크기를 확장.\n",
    "    - **A 텐서가 1차원일 경우**: A 텐서의 크기가 (m,) 이면 m 은 고정하고 (x, m)의 크기로만 확장가능\n",
    "    - **A 텐서가 2차원 이상일 경우**: 크기가 1인 차원에 대해서만 적용가능. A 텐서의 크기가 (1, m)이면 (x, m), (m, 1) 이면 (x, y)로만 가능\n",
    "- `repeat`: 텐서를 반복하여 크기를 확장\n",
    "    - e.g. A 텐서가 (m,n) 크기를 가진다하고, A 텐서를 repeat(i, j)를 하면 결과 값으로 (m x i, n x j) 크기의 텐서가 생성됨.\n",
    "- `flatten`: 다차원 텐서를 1차원 텐서로 변경\n",
    "- `ravel`: 다차원 텐서를 1차원 텐서로 변경\n",
    "\n",
    "📚 Reference: \n",
    "* [unsqueeze] : https://pytorch.org/docs/stable/generated/torch.unsqueeze.html\n",
    "* [squeeze] : https://pytorch.org/docs/stable/generated/torch.squeeze.html\n",
    "* [expand] : https://pytorch.org/docs/stable/generated/torch.Tensor.expand.html\n",
    "* [repeat] : https://pytorch.org/docs/stable/generated/torch.Tensor.repeat.html\n",
    "* [flatten] : https://pytorch.org/docs/stable/generated/torch.flatten.html\n",
    "* [ravel] : https://pytorch.org/docs/stable/generated/torch.ravel.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
